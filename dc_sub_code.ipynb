{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a4136f",
   "metadata": {},
   "source": [
    "## 第一问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StandardScaler()\n",
    "fX = mol.values\n",
    "fX_trans = ssc.fit_transform(fX)\n",
    "fy = erapi.values\n",
    "\n",
    "# remove features with zero variance\n",
    "n_zero_var = 0\n",
    "zero_var_cols = []\n",
    "for i in range(len(sel_vars)):\n",
    "    if sel_vars[i] == 0:\n",
    "        zero_var_cols.append(mol.columns[i])\n",
    "        n_zero_var += 1\n",
    "fil_cols = list(set(mol.columns).difference(set(zero_var_cols)))\n",
    "mol_fil = mol[fil_cols].copy()\n",
    "\n",
    "# randomforest selection\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=2, max_depth=4,random_state=300)\n",
    "rf_scores = []\n",
    "# select individual feature and do cross-validation\n",
    "for i in range(fX_fil.shape[1]):\n",
    "    score = cross_val_score(rf,fX_fil[:, i:i+1], fy, scoring=\"r2\", cv=ShuffleSplit(10, test_size=0.3))\n",
    "    rf_scores.append((format(np.mean(score), '.3f'), mol_fil.columns[i]))\n",
    "rf_columns = sorted(rf_scores, reverse=True)[:20]\n",
    "rf_columns = [v[1] for v in rf_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d3024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-17T20:11:14.119016Z",
     "start_time": "2021-10-17T20:11:14.115535Z"
    }
   },
   "source": [
    "## 第二问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Validation function\n",
    "n_folds = 5\n",
    "train = train_X\n",
    "def mse_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=100).get_n_splits(train_X)\n",
    "    mse = -cross_val_score(model, train_X, train_y, scoring=\"neg_mean_squared_error\", cv = kf)\n",
    "    return mse\n",
    "\n",
    "# utilize individual model\n",
    "lasso = make_pipeline(StandardScaler(), Lasso(alpha =0.005, random_state=100))\n",
    "ENet = make_pipeline(StandardScaler(), ElasticNet(max_iter=3000,alpha=0.0005, l1_ratio=.9, random_state=100))\n",
    "KRR = GridSearchCV(KernelRidge(), param_grid=[\n",
    "                {'alpha':[0.1,0.3,0.9,1.2,1.5,2.0], 'degree':[2,3,4],'coef0':[1,2.5]}\n",
    "            ],cv=3,scoring='neg_mean_squared_error')\n",
    "\n",
    "RFR = RandomForestRegressor(n_estimators=100,criterion='mse', random_state=0)\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "score = mse_cv(lasso)\n",
    "print(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = mse_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = mse_cv(RFR)\n",
    "print(\"RandomForestRegressor score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = mse_cv(GBoost)\n",
    "print(\"GBoost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "score = mse_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)\n",
    "    \n",
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, RFR ,GBoost),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = mse_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "# stack model performance\n",
    "stacked_averaged_models.fit(train_X, train_y)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train_X)\n",
    "stacked_pred = stacked_averaged_models.predict(test_X)\n",
    "\n",
    "model_xgb.fit(train_X, train_y)\n",
    "xgb_train_pred = model_xgb.predict(train_X)\n",
    "xgb_pred = model_xgb.predict(test_X)\n",
    "\n",
    "model_lgb.fit(train, train_y)\n",
    "lgb_train_pred = model_lgb.predict(train_X)\n",
    "lgb_pred = model_lgb.predict(test_X)\n",
    "\n",
    "print('Stack model MSE', mean_squared_error(train_y, stacked_train_pred))\n",
    "print('XGBoost regression MSE',mean_squared_error(train_y, xgb_train_pred))\n",
    "print('LightGBM regression MSE: ', mean_squared_error(train_y, lgb_train_pred))\n",
    "print('MSE score on train data:', mean_squared_error(train_y,stacked_train_pred*0.70 +\n",
    "               xgb_train_pred*0.25 + lgb_train_pred*0.05 ))\n",
    "\n",
    "ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15\n",
    "# convert pIC50 to IC50_nM: 10^(-y+9)\n",
    "result = np.power(10,(-ensemble + 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efef4670",
   "metadata": {},
   "source": [
    "## 第三问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "\n",
    "def LR(X_train,y_train,X_test,y_test): \n",
    "    # Standardization\n",
    "    ssc = StandardScaler()\n",
    "    X_train_trans = ssc.fit_transform(X_train)\n",
    "    X_test_trans = ssc.transform(X_test)\n",
    "    lr = LogisticRegression()                                     \n",
    "    lr.fit(X_train_trans,y_train)              \n",
    "    y_prob = lr.predict_proba(X_test_trans)[:,1]                           \n",
    "    y_pred = lr.predict(X_test_trans)                                      \n",
    "    fpr_lr,tpr_lr,threshold_lr = metrics.roc_curve(y_test,y_prob)   \n",
    "    auc_lr = metrics.auc(fpr_lr,tpr_lr)                             \n",
    "    score_lr = metrics.accuracy_score(y_test,y_pred)                 \n",
    "    print([score_lr,auc_lr])\n",
    "    return lr, fpr_lr,tpr_lr,auc_lr,score_lr\n",
    "\n",
    "def SVC_(X_train,y_train,X_test,y_test):\n",
    "    # SVM with standardization\n",
    "    ssc = StandardScaler()\n",
    "    X_train_trans = ssc.fit_transform(X_train)\n",
    "    X_test_trans = ssc.transform(X_test)\n",
    "    kernelList = ['linear','rbf','sigmoid']\n",
    "    svc = None\n",
    "    auc_svc = -1\n",
    "    score_svc = -1\n",
    "    fpr_svc = None\n",
    "    tpr_svc = None\n",
    "    for kernel in kernelList:\n",
    "        svc_tmp = SVC(kernel=kernel).fit(X_train_trans,y_train)\n",
    "\n",
    "        # decision border distance\n",
    "        y_prob = svc_tmp.decision_function(X_test_trans)\n",
    "        y_pred = svc_tmp.predict(X_test_trans)\n",
    "        # false positive, true positive\n",
    "        fpr_svc_tmp,tpr_svc_tmp,threshold_svc_tmp = metrics.roc_curve(y_test,y_prob)\n",
    "        # auc curve\n",
    "        auc_svc_tmp = metrics.auc(fpr_svc_tmp,tpr_svc_tmp)\n",
    "        score_svc_tmp = metrics.accuracy_score(y_test,y_pred)\n",
    "        print([score_svc_tmp,auc_svc_tmp])    \n",
    "\n",
    "        if not svc:\n",
    "            svc = svc_tmp\n",
    "        if auc_svc < auc_svc_tmp:\n",
    "            auc_svc = auc_svc_tmp\n",
    "            best_svc = svc\n",
    "            score_svc = score_svc_tmp\n",
    "            fpr_svc = fpr_svc_tmp\n",
    "            tpr_svc = tpr_svc_tmp\n",
    "    return svc, fpr_svc, tpr_svc, auc_svc, score_svc\n",
    "\n",
    "def KNN(X_train,y_train,X_test,y_test):\n",
    "    # KNN with standardization\n",
    "    ssc = StandardScaler()\n",
    "    X_train_trans = ssc.fit_transform(X_train)\n",
    "    X_test_trans = ssc.transform(X_test)\n",
    "    \n",
    "    # find best K value\n",
    "    score_K=[]\n",
    "    KList=range(2,10)\n",
    "    for k in KList:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k,weights='distance').fit(X_train_trans,y_train)\n",
    "        score_K.append(knn.score(X_test_trans,y_test))\n",
    "    print('K={}, get highest score={}'.format(KList[score_K.index(max(score_K))],max(score_K)))\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=KList[score_K.index(max(score_K))],\n",
    "                               weights='distance').fit(X_train_trans,y_train)\n",
    "\n",
    "    y_prob = knn.predict_proba(X_test_trans)[:,1]                              \n",
    "    y_pred = knn.predict(X_test_trans)                                       \n",
    "    fpr_knn,tpr_knn,threshold_knn = metrics.roc_curve(y_test,y_prob)   \n",
    "    auc_knn = metrics.auc(fpr_knn,tpr_knn)                              \n",
    "    score_knn = metrics.accuracy_score(y_test,y_pred)\n",
    "    print([score_knn,auc_knn])\n",
    "    return knn, fpr_knn, tpr_knn, auc_knn, score_knn\n",
    "\n",
    "def DTC(X_train,y_train,X_test,y_test):\n",
    "    # decision tree\n",
    "    dtc = tree.DecisionTreeClassifier()                         \n",
    "    dtc.fit(X_train,y_train)                                       \n",
    "    y_prob = dtc.predict_proba(X_test)[:,1]                          \n",
    "    y_pred = dtc.predict(X_test)                                      \n",
    "    fpr_dtc,tpr_dtc,threshod_dtc= metrics.roc_curve(y_test,y_prob)   \n",
    "    score_dtc = metrics.accuracy_score(y_test,y_pred)                \n",
    "    auc_dtc = metrics.auc(fpr_dtc,tpr_dtc) \n",
    "    print([score_dtc,auc_dtc])\n",
    "    return dtc, fpr_dtc, tpr_dtc, auc_dtc, score_dtc\n",
    "\n",
    "def RFC(X_train,y_train,X_test,y_test):\n",
    "    # random forest classifier\n",
    "    rfc = RandomForestClassifier()                                     \n",
    "    rfc.fit(X_train,y_train)                                           \n",
    "    y_prob = rfc.predict_proba(X_test)[:,1]               \n",
    "    y_pred = rfc.predict(X_test)\n",
    "    fpr_rfc,tpr_rfc,threshold_rfc = metrics.roc_curve(y_test,y_prob)    \n",
    "    auc_rfc = metrics.auc(fpr_rfc,tpr_rfc)                \n",
    "    score_rfc = metrics.accuracy_score(y_test,y_pred)                \n",
    "    print([score_rfc,auc_rfc])\n",
    "    return rfc, fpr_rfc, tpr_rfc, auc_rfc, score_rfc\n",
    "    \n",
    "def ADA(X_train,y_train,X_test,y_test):\n",
    "    # AdaBoost Classifier\n",
    "    # use weak classifier\n",
    "    adaclf = AdaBoostClassifier(\n",
    "        DecisionTreeClassifier(max_depth=1),\n",
    "        n_estimators=100\n",
    "    )\n",
    "    adaclf.fit(X_train, y_train)\n",
    "    y_pred = adaclf.predict(X_test)\n",
    "    # print('adaboost confusion matrix:')\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    fpr_ada,tpr_ada,threshold_ada = metrics.roc_curve(y_test,y_pred)    \n",
    "    auc_ada = metrics.auc(fpr_ada,tpr_ada)                             \n",
    "    score_ada = metrics.accuracy_score(y_test,y_pred)  \n",
    "    print('[{},{}]'.format(score_ada,auc_ada))\n",
    "    return adaclf, fpr_ada, tpr_ada, auc_ada, score_ada\n",
    "\n",
    "def XGB(X_train,y_train,X_test,y_test):\n",
    "    # XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train) \n",
    "    dtest=xgb.DMatrix(X_test)\n",
    "\n",
    "    params={'booster':'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'max_depth':4,\n",
    "        'lambda': 10,\n",
    "        'gamma':0.1,\n",
    "        'subsample':0.75,\n",
    "        'colsample_bytree':0.75,\n",
    "        'min_child_weight':3,\n",
    "        'eta': 0.025,\n",
    "        'seed':10,\n",
    "        'nthread':-1,\n",
    "         'silent':1,\n",
    "        'verbosity':0}\n",
    "\n",
    "    watchlist = [(dtrain,'train')]\n",
    "    bst=xgb.train(params,dtrain,num_boost_round=100,evals=watchlist)\n",
    "\n",
    "    ypred=bst.predict(dtest)\n",
    "    y_pred = (ypred >= 0.5)*1\n",
    "\n",
    "    fpr_xgb,tpr_xgb,threshold_xgb = metrics.roc_curve(y_test,ypred)\n",
    "    auc_xgb = metrics.auc(fpr_xgb,tpr_xgb)\n",
    "    score_xgb = metrics.accuracy_score(y_test,y_pred)  \n",
    "    print ('AUC: %.4f' % metrics.auc(fpr_xgb,tpr_xgb))\n",
    "    print ('ACC: %.4f' % metrics.accuracy_score(y_test,y_pred))\n",
    "    print(metrics.confusion_matrix(y_test,y_pred))\n",
    "    return bst, fpr_xgb, tpr_xgb, auc_xgb, score_xgb\n",
    "    \n",
    "def LGBM(X_train,y_train,X_test,y_test):\n",
    "    # LightGBM\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train) \n",
    "    dtest=lgb.Dataset(X_test,label=y_test)\n",
    "\n",
    "    params = {'num_leaves': 60,\n",
    "              'min_data_in_leaf': 20,\n",
    "              'objective': 'binary',\n",
    "              'max_depth': -1,\n",
    "              'learning_rate': 0.03,\n",
    "              \"min_sum_hessian_in_leaf\": 6,\n",
    "              \"boosting\": \"gbdt\",\n",
    "              \"feature_fraction\": 0.9,\n",
    "              \"bagging_freq\": 1,\n",
    "              \"bagging_fraction\": 0.8,\n",
    "              \"bagging_seed\": 11,\n",
    "              \"lambda_l1\": 0,\n",
    "              'lambda_l2': 0.001,\n",
    "              \"verbosity\": 0,\n",
    "              \"nthread\": -1,\n",
    "              'metric': {'binary_logloss', 'auc'},\n",
    "              \"random_state\": 2021,\n",
    "              }\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                    dtrain,\n",
    "                    num_boost_round=100,\n",
    "                    valid_sets=dtest,\n",
    "                    early_stopping_rounds=50)\n",
    "    ypred=gbm.predict(X_test)\n",
    "    y_pred = (ypred >= 0.5)*1\n",
    "\n",
    "    fpr_gbm,tpr_gbm,threshold_gbm = metrics.roc_curve(y_test,ypred)\n",
    "    auc_gbm = metrics.auc(fpr_gbm,tpr_gbm)\n",
    "    score_gbm = metrics.accuracy_score(y_test,y_pred)  \n",
    "    print ('AUC: %.4f' % metrics.auc(fpr_gbm,tpr_gbm))\n",
    "    print ('ACC: %.4f' % metrics.accuracy_score(y_test,y_pred))\n",
    "    return gbm, fpr_gbm, tpr_gbm, auc_gbm, score_gbm\n",
    "\n",
    "\n",
    "def plot_acc_curve(prs,name,best_mn):\n",
    "    # comparison between different approaches\n",
    "    plt.style.use('bmh')\n",
    "    plt.figure(figsize=(15,12))\n",
    "    #设置坐标刻度值的大小以及刻度值的字体\n",
    "    plt.tick_params(labelsize=15)\n",
    "    \n",
    "    name_items = []\n",
    "    score_items = []\n",
    "    for k,v in prs.items():\n",
    "        name_items.append(k)\n",
    "        score_items.append(v[2])\n",
    "    colors = ['grey' if n!= best_mn else 'lightskyblue' for n in name_items]\n",
    "\n",
    "    plt.bar(name_items,score_items,align='center',width=0.8,\n",
    "            color=colors,alpha=0.9)\n",
    "    indexs=np.arange(len(name_items))\n",
    "    for x,y in zip(indexs,score_items):\n",
    "        plt.text(x, y+0.01,'%.3f' % y, ha='center',va='bottom')\n",
    "\n",
    "    plt.legend(loc='lower right',prop={'size':25})\n",
    "    plt.xlabel('Classifier',fontsize=12)\n",
    "    plt.ylabel('Accuracy Rate',fontsize=12)\n",
    "    plt.title('{} Accuracy Rate Comparison'.format(name))\n",
    "    plt.savefig('{}_acc_score.jpg'.format(name))\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(prs,name):\n",
    "    plt.style.use('bmh')\n",
    "    plt.figure(figsize=(15,12))\n",
    "    for k,v in prs.items():\n",
    "        plt.plot(v[0],v[1],label=k)            \n",
    "\n",
    "    plt.legend(loc='lower right',prop={'size':25})\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('{} ROC Curve'.format(name))\n",
    "    plt.savefig('{}_roc_curve.jpg'.format(name))\n",
    "    plt.show()\n",
    "    \n",
    "def clf_train(X,y,name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,random_state=100)\n",
    "    model_params = (X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    lr, fpr_lr,tpr_lr,auc_lr,score_lr = LR(*model_params)\n",
    "    svc, fpr_svc ,tpr_svc,auc_svc,score_svc = SVC_(*model_params)\n",
    "    knn, fpr_knn,tpr_knn,auc_knn,score_knn = KNN(*model_params)\n",
    "    dtc, fpr_dtc,tpr_dtc,auc_dtc,score_dtc = DTC(*model_params)\n",
    "    rfc, fpr_rfc,tpr_rfc,auc_rfc,score_rfc = RFC(*model_params)\n",
    "    ada, fpr_ada,tpr_ada,auc_ada,score_ada = ADA(*model_params)\n",
    "    bst, fpr_xgb,tpr_xgb,auc_xgb,score_xgb = XGB(*model_params)\n",
    "    gbm, fpr_gbm,tpr_gbm,auc_gbm,score_gbm = LGBM(*model_params)\n",
    "    \n",
    "    ret = {\n",
    "        'lr': (fpr_lr,tpr_lr,score_lr,auc_lr,lr), \n",
    "        'svc':(fpr_svc,tpr_svc,score_svc,auc_svc,svc),\n",
    "        'knn':(fpr_knn,tpr_knn,score_knn,auc_knn,knn),\n",
    "        'dtc':(fpr_dtc,tpr_dtc,score_dtc,auc_dtc,dtc),\n",
    "        'rfc':(fpr_rfc,tpr_rfc,score_rfc,auc_rfc,rfc),\n",
    "        'ada':(fpr_ada,tpr_ada,score_ada,auc_ada,ada),\n",
    "        'xgb':(fpr_xgb,tpr_xgb,score_xgb,auc_xgb,bst),\n",
    "        'gbm':(fpr_gbm,tpr_gbm,score_gbm,auc_gbm,gbm)\n",
    "    }\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def clf_predict(ret,Xtest,name):\n",
    "    plot_roc_curve(ret,name)\n",
    "    # AUC score comparison\n",
    "    best_mn = ''\n",
    "    best_m = None\n",
    "    highest_score = -1\n",
    "    for k,v in ret.items():\n",
    "        # compare accuracy first\n",
    "        if v[2] > highest_score:\n",
    "            highest_score = v[2]\n",
    "            highes_auc_score = v[-2]\n",
    "            best_mn = k\n",
    "            best_m = v[-1]\n",
    "        elif v[2] == highest_score:\n",
    "            if v[-2] > highes_auc_score:\n",
    "                highest_score = v[2]\n",
    "                highes_auc_score = v[-2]\n",
    "                best_mn = k\n",
    "                best_m = v[-1]\n",
    "    print('{} get highest acc score({}), applied to compound: {}, auc_score({})'\n",
    "          .format(best_mn,highest_score,name,highes_auc_score))\n",
    "\n",
    "    if best_mn == 'xgb':\n",
    "        Dtest = xgb.DMatrix(Xtest)\n",
    "        y_final_test = (best_m.predict(Dtest) >= 0.5) * 1\n",
    "    elif best_mn == 'gbm':\n",
    "        y_final_test = (best_m.predict(Xtest) >= 0.5) * 1\n",
    "    else:\n",
    "        y_final_test = best_m.predict(Xtest)\n",
    "    best_item = {name:(best_mn,best_m)}\n",
    "    plot_acc_curve(ret,name,best_mn)\n",
    "    return y_final_test, best_item\n",
    "\n",
    "\n",
    "# 比较各个分类器的效果，绘制准确度柱状图和 ROC曲线图\n",
    "compound_names = ['Caco-2','CYP3A4','hERG','HOB']\n",
    "compound_rets = []\n",
    "\n",
    "# training different model in different compounds\n",
    "for name in compound_names:\n",
    "    compound_rets.append(clf_train(fX, adm_train[name].values,name))\n",
    "\n",
    "    \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# 对于样本不平衡的 ‘MN’化合物的负样本进行过采样处理\n",
    "smo = SMOTE(sampling_strategy=0.5,random_state=100)\n",
    "fX_smo, y_mn_smo = smo.fit_resample(fX,adm_train['MN'])\n",
    "fX_smo.shape, y_mn_smo.shape\n",
    "\n",
    "mn_ret = clf_train(fX_smo,y_mn_smo,'MN')\n",
    "compound_names.append('MN')\n",
    "compound_rets.append(mn_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d2bd7",
   "metadata": {},
   "source": [
    "## 第四问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78cb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出至少满足三种ADMET性质的样本，按照pIC50生物活性值逆序排列，找到活性最好那个样本\n",
    "d_adm['pIC50'] = d_pic['pIC50']\n",
    "d_adm['dis'] = d_adm.apply(lambda x: x[cols[1]] + x[cols[2]] +x[cols[4]] - x[cols[0]] - x[cols[3]],axis=1)\n",
    "d_fil = d_adm[d_adm['dis'] <= 0]\n",
    "suit_index = d_fil.sort_values(by='pIC50',ascending=False).index[0]\n",
    "# suit_sample = d_mol[rf_columns].iloc[suit_index]\n",
    "suit_sample = d_mol.iloc[suit_index]\n",
    "suit_src_admet = d_adm.iloc[suit_index]\n",
    "\n",
    "def sat_con(ap):\n",
    "    return ap[1] + ap[2] + ap[4] - ap[0] - ap[3] <= 0\n",
    "def get_pred_admet(sample):\n",
    "    admet_pred = []\n",
    "    for item in compound_best_items:\n",
    "        item = list(item.values())[0]\n",
    "        m_name = item[0]\n",
    "        m = item[1]\n",
    "        if m_name == 'xgb':\n",
    "            Dtest = xgb.DMatrix(sample)\n",
    "            pred = (m.predict(Dtest) >= 0.5) * 1\n",
    "        elif m_name == 'gbm':\n",
    "            pred = (m.predict(sample) >= 0.5) * 1\n",
    "        else:\n",
    "            pred = m.predict(sample)\n",
    "        admet_pred.append(pred[0])\n",
    "    return admet_pred\n",
    "\n",
    "def find_border(col,x,ix,itval,ty):\n",
    "    ori_val = x[0,ix]\n",
    "    max_val = d_mol[col].max()\n",
    "    min_val = d_mol[col].min()\n",
    "\n",
    "    left = ori_val\n",
    "    right = ori_val\n",
    "    # when original value == 0\n",
    "    if itval == 0.0:\n",
    "        itval = abs(max_val / 100.0)\n",
    "        if itval == 0: return {'column':col,'type':'连续', 'value':0.0}\n",
    "\n",
    "    # start looping to find border\n",
    "    while x[0,ix] >= min_val and sat_con(get_pred_admet(x)) :\n",
    "        x[0,ix] -= itval\n",
    "    left = x[0,ix] + itval\n",
    "    x[0,ix] = ori_val\n",
    "    while x[0,ix] <= max_val and sat_con(get_pred_admet(x)) :\n",
    "        x[0,ix] += itval\n",
    "    right = x[0,ix] - itval\n",
    "    print('\"{}\" found border: ({}, {})'.format(col,left,right))\n",
    "    return {'column':col,'type':ty,'left':left,'right':right}\n",
    "\n",
    "# x2 + x3 + x5 - x1 - x4 <= 0\n",
    "ssam = suit_sample.values.reshape(1,-1)\n",
    "areas_col = []\n",
    "for col in fea_columns:\n",
    "    x = ssam.copy()\n",
    "    ix = d_mol.columns.to_list().index(col)\n",
    "    # categorical or continuous\n",
    "    if d_mol[col].dtype == int:\n",
    "        itval = 1\n",
    "        areas_col.append(find_border(col,x,ix,itval,'离散'))\n",
    "            \n",
    "    elif d_mol[col].dtype == float:\n",
    "        itval = abs(x[0,ix] / 10.0)\n",
    "        areas_col.append(find_border(col,x,ix,itval,'连续'))\n",
    "    \n",
    "print('最终的分子描述符及其取值范围: '，areas_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac",
   "language": "python",
   "name": "prac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
